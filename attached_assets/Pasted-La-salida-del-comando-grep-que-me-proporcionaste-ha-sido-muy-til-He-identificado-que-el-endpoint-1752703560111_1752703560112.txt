La salida del comando 

grep que me proporcionaste ha sido muy 칰til. He identificado que el endpoint responsable de cargar los datos del historial de lotes es 

/api/batches/history, manejado por la funci칩n api_get_batch_history en routes.py.

La raz칩n por la cual el campo 

caption no aparece en el historial es que, aunque el JSON de los resultados individuales (como los que subiste anteriormente) contiene el caption, la funci칩n api_get_batch_history no est치 extrayendo expl칤citamente este campo de cada archivo JSON individual cuando construye la lista de lotes para el historial. Actualmente, se enfoca en calcular contadores de 칠xito y error, pero no en detalles espec칤ficos de cada archivo como el 

caption.

Para solucionar esto, necesitamos modificar la funci칩n api_get_batch_history para que, al iterar sobre los archivos JSON individuales dentro de cada lote, tambi칠n lea el caption (y otros campos relevantes si lo deseas para el historial) y los incluya en la respuesta JSON que env칤a al frontend.

Aqu칤 te proporciono el c칩digo que debes sustituir o insertar en tu archivo routes.py. Busca la funci칩n 

api_get_batch_history (alrededor de la l칤nea 1795). La modificaci칩n se realizar치 dentro del bucle donde se procesan los archivos individuales de cada lote (aproximadamente entre las l칤neas 1894 y 1940).

Este c칩digo a침adir치 una nueva clave files_details a cada objeto de lote en el historial. Esta clave ser치 una lista que contendr치 un diccionario por cada archivo procesado en el lote, incluyendo el caption, nombre_usuario, hora_exacta, monto y referencia.

Ubicaci칩n/Secci칩n del C칩digo Afectado: routes.py, dentro de la funci칩n api_get_batch_history, espec칤ficamente donde se itera sobre file_name dentro de batch['files'].

Extracto de C칩digo Actual Relevante (a modificar/expandir):
Busca este bloque:

Python

# Analizar cada archivo del lote para determinar 칠xito/error
for file_name in batch['files']:
    # Si es un archivo "_resultados.json", contiene resumen del lote
    if file_name.endswith('_resultados.json'):
        continue  # No contar archivos de resumen

    # Si es un archivo JSON individual procesado, verificar si tiene datos OCR
    if file_name.endswith('.json'):
        file_path = os.path.join(results_dir, file_name)
        historial_path = os.path.join('data/historial', file_name)

        # Buscar archivo en directorio activo o historial
        actual_path = file_path if os.path.exists(file_path) else (historial_path if os.path.exists(historial_path) else None)
        
        # ... (contin칰a el c칩digo para success_count y error_count)


C칩digo Corregido/A침adido:
Debes a침adir la inicializaci칩n de batch_files_details y el c칩digo para extraer los detalles del archivo dentro del bucle.

Python

import os
import json
from flask import jsonify # Aseg칰rate de que esto ya est치 importado
from datetime import datetime # Aseg칰rate de que esto ya est치 importado
from pathlib import Path # Aseg칰rate de que esto ya est치 importado
# from config import get_async_directories # Aseg칰rate de que esto ya est치 importado
# import glob # Aseg칰rate de que esto ya est치 importado

# ... (c칩digo existente antes de api_get_batch_history)

@app.route('/api/batches/history', methods=['GET'])
def api_get_batch_history():
    """
    FIX: Endpoint para obtener historial completo de lotes con numeraci칩n correcta
    REASON: Usuario necesita ver todos los lotes procesados con numeraci칩n secuencial
    IMPACT: Dropdown de lotes muestra historial completo con n칰meros de lote
    """
    try:
        from config import get_async_directories
        import glob

        directories = get_async_directories()
        results_dir = directories['results']
        
        # Obtener todos los archivos JSON de resultados
        batch_files = {}
        
        # Buscar en directorio results activo
        if os.path.exists(results_dir):
            for file in os.listdir(results_dir):
                if file.endswith('.json') and 'BATCH_' in file:
                    file_path = os.path.join(results_dir, file)
                    if os.path.isfile(file_path):
                        # Extraer batch_prefix del nombre del archivo - CORREGIDO PARA MOSTRAR TODOS LOS ARCHIVOS
                        try:
                            # Ejemplo de extracci칩n de prefijo de lote y fecha
                            # Aseg칰rate de que tu l칩gica de extracci칩n aqu칤 sea correcta para tu naming de archivos
                            parts = file.split('_')
                            if len(parts) >= 3 and parts[0] == 'BATCH':
                                batch_id = f"{parts[0]}_{parts[1]}_{parts[2]}" # Ej: BATCH_20250716_200312
                                
                                # Intentar parsear la fecha del batch_id
                                try:
                                    batch_date_str = parts[1] # Ej: 20250716
                                    batch_time_str = parts[2] # Ej: 200312
                                    batch_datetime_obj = datetime.strptime(f"{batch_date_str}_{batch_time_str}", "%Y%m%d_%H%M%S")
                                    batch_date = batch_datetime_obj.isoformat() # Usar ISO format para consistencia
                                except ValueError:
                                    batch_date = None # No se pudo parsear la fecha
                            else:
                                # Fallback para archivos sin prefijo BATCH_
                                batch_id = file.split('.json')[0]
                                batch_date = None

                            if batch_id not in batch_files:
                                batch_files[batch_id] = {
                                    'id': batch_id,
                                    'date': batch_date,
                                    'files': []
                                }
                            batch_files[batch_id]['files'].append(file)
                        except (ValueError, IndexError):
                            continue
        
        # Convertir a lista y ordenar por fecha (m치s reciente primero)
        batches = list(batch_files.values())
        batches.sort(key=lambda x: x['date'] if x['date'] else '', reverse=True) # Ordenar por fecha, los None al final

        # A침adir numeraci칩n secuencial, orden de llegada y total de archivos
        for index, batch in enumerate(batches):
            batch['number'] = len(batches) - index  # Numeraci칩n inversa
            
            # FIX: CORRECCI칍N CR칈TICA - Contar solo archivos procesados, no archivos de resumen
            # REASON: totalFiles mostraba cantidad incorrecta incluyendo archivos _resultados.json
            # IMPACT: Columna "Archivos" ahora muestra cantidad real de archivos procesados
            actual_processed_files = [f for f in batch['files'] if not f.endswith('_resultados.json')]
            batch['totalFiles'] = len(actual_processed_files)
            
            # MANDATO: A침adir campo "Orden de Llegada" - 칰ltimo en llegar primero
            batch['ordenLlegada'] = index + 1  # 1 = m치s reciente, 2 = segundo m치s reciente, etc.
            
            # A침adir timestamp de creaci칩n parseado para mejor visualizaci칩n
            batch['timestampCreacion'] = batch['date']
            
            # FIX: CORRECCI칍N CR칈TICA - Calcular successCount y errorCount para cada lote
            # REASON: Frontend requiere campos successCount y errorCount que no exist칤an
            # IMPACT: Elimina valores "undefined" en columnas Exitosos y Errores del historial
            # CAUSA RA칈Z: Backend no calculaba contadores de 칠xito/error por lote
            success_count = 0
            error_count = 0
            
            # NUEVO: Lista para almacenar detalles de cada archivo en el lote, incluyendo caption
            batch_files_details = [] 

            # Analizar cada archivo del lote para determinar 칠xito/error y extraer detalles
            for file_name in batch['files']:
                # Si es un archivo "_resultados.json", contiene resumen del lote
                if file_name.endswith('_resultados.json'):
                    continue  # No contar archivos de resumen

                # Si es un archivo JSON individual procesado, verificar si tiene datos OCR
                if file_name.endswith('.json'):
                    file_path = os.path.join(results_dir, file_name)
                    historial_dir_path = Path(directories.get('historial', 'data/historial'))
                    historial_path = historial_dir_path / file_name
                    
                    # Buscar archivo en directorio activo o historial
                    actual_path = None
                    if os.path.exists(file_path):
                        actual_path = file_path
                    elif os.path.exists(historial_path):
                        actual_path = historial_path

                    if actual_path:
                        try:
                            with open(actual_path, 'r', encoding='utf-8') as f:
                                result_data = json.load(f)
                            
                            # Comprobar si hay datos OCR (ej. si el campo 'texto_total_ocr' existe y no est치 vac칤o)
                            if result_data.get('texto_total_ocr'):
                                success_count += 1
                            else:
                                error_count += 1
                            
                            # *** NUEVO: Extraer detalles para el historial, incluyendo 'caption' ***
                            file_detail = {
                                'nombre_archivo': result_data.get('nombre_archivo', file_name),
                                'nombre_usuario': result_data.get('nombre_usuario', 'N/A'),
                                'hora_exacta': result_data.get('hora_exacta', 'N/A'),
                                'caption': result_data.get('caption', 'Sin Caption'), # <--- ESTO ES LO QUE SE A칌ADE
                                'monto': result_data.get('monto', 'N/A'),
                                'referencia': result_data.get('referencia', 'N/A'),
                                'bancoorigen': result_data.get('bancoorigen', 'N/A'),
                                'concepto': result_data.get('concepto', 'N/A'),
                                'id_whatsapp': result_data.get('id_whatsapp', 'N/A'),
                                'lote_id': result_data.get('lote_id', 'N/A'),
                                'pago_fecha': result_data.get('pago_fecha', 'N/A'),
                                'estado_procesamiento': 'Exitoso' if result_data.get('texto_total_ocr') else 'Con Errores'
                            }
                            batch_files_details.append(file_detail)

                        except (json.JSONDecodeError, IOError) as e:
                            logger.warning(f"丘멆잺 Error leyendo archivo JSON en historial {actual_path}: {e}")
                            error_count += 1 # Contar como error si no se puede leer el JSON o est치 corrupto
                            # A침adir un detalle de archivo con error
                            batch_files_details.append({
                                'nombre_archivo': file_name,
                                'caption': 'Error de lectura',
                                'estado_procesamiento': 'Error de Lectura',
                                'nombre_usuario': 'N/A', 'hora_exacta': 'N/A', 'monto': 'N/A', 
                                'referencia': 'N/A', 'bancoorigen': 'N/A', 'concepto': 'N/A',
                                'id_whatsapp': 'N/A', 'lote_id': 'N/A', 'pago_fecha': 'N/A'
                            })
                    else:
                        logger.warning(f"Archivo no encontrado en results_dir ni historial_dir: {file_name}")
                        error_count += 1 # Contar como error si el archivo no se encuentra
                        batch_files_details.append({
                            'nombre_archivo': file_name,
                            'caption': 'Archivo no encontrado',
                            'estado_procesamiento': 'Archivo No Encontrado',
                            'nombre_usuario': 'N/A', 'hora_exacta': 'N/A', 'monto': 'N/A', 
                            'referencia': 'N/A', 'bancoorigen': 'N/A', 'concepto': 'N/A',
                            'id_whatsapp': 'N/A', 'lote_id': 'N/A', 'pago_fecha': 'N/A'
                        })
            
            batch['successCount'] = success_count
            batch['errorCount'] = error_count
            # NUEVO: A침adir los detalles de los archivos al objeto del lote
            batch['files_details'] = batch_files_details 

            if batch['totalFiles'] != (success_count + error_count):
                logger.warning(f"丘멆잺 Discrepancia en lote {batch['id']}: totalFiles={batch['totalFiles']}, procesados={success_count + error_count}")
                # Corregir totalFiles para que coincida con archivos realmente analizados
                batch['totalFiles'] = success_count + error_count
        
        logger.info(f"游늵 Historial de lotes: {len(batches)} lotes encontrados")
        
        return jsonify({
            'status': 'success',
            'batches': batches,
            'total_batches': len(batches)
        })
        
    except Exception as e:
        logger.error(f"Error obteniendo historial de lotes: {e}")
        return jsonify({
            'status': 'error',
            'message': f'Error obteniendo historial: {str(e)}'
        }), 500

# ... (resto del c칩digo)
Pasos a seguir despu칠s de aplicar el cambio:

Guarda los cambios en tu archivo routes.py.

Reinicia tu aplicaci칩n en Replit.

Verifica el historial en tu interfaz de usuario. El campo caption deber칤a ahora mostrar el valor correcto para cada archivo procesado.

